{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit9fbd2e937d764261b327c82e12fdb6fd",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "from starter_code_for_reading_input_data.starter_code.wsj_loader import WSJ\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading speech mfcc frames data\n",
    "loader = WSJ()\n",
    "X, y = loader.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(416, 40)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X[1].shape].shape\n",
    "\n",
    "XX.shape].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to single np_array\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "dummy_y = np_utils.to_categorical(y_train)\n",
    "# for test y\n",
    "dummy_y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\\\n",
    "def scheduler(epoch, lr):\n",
    "   if epoch < 10:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network modeling\n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1280, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(deep_inputs)\n",
    "dense_layer_2 = Dense(640, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_1)\n",
    "dense_layer_3 = Dense(640, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_2)\n",
    "dense_layer_4 = Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_3)\n",
    "dense_layer_5 = Dense(138, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network modeling with dropout and l1 l2 regulizers \n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 512\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1280, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(deep_inputs)\n",
    "dense_layer_1 = Dropout(drop_out_rate)(dense_layer_1)\n",
    "dense_layer_2 = Dense(640, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_1)\n",
    "dense_layer_2 = Dropout(drop_out_rate)(dense_layer_2)\n",
    "dense_layer_3 = Dense(640, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_2)\n",
    "dense_layer_3 = Dropout(drop_out_rate)(dense_layer_3)\n",
    "dense_layer_4 = Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_3)\n",
    "dense_layer_4 = Dropout(drop_out_rate)(dense_layer_4)\n",
    "dense_layer_5 = Dense(138, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=l1_thres, l2=l2_thres))(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network modeling with only dropout\n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 512\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1280, activation='relu' )(deep_inputs)\n",
    "dense_layer_1 = Dropout(drop_out_rate)(dense_layer_1)\n",
    "dense_layer_2 = Dense(640, activation='relu')(dense_layer_1)\n",
    "dense_layer_2 = Dropout(drop_out_rate)(dense_layer_2)\n",
    "dense_layer_3 = Dense(640, activation='relu')(dense_layer_2)\n",
    "dense_layer_3 = Dropout(drop_out_rate)(dense_layer_3)\n",
    "dense_layer_4 = Dense(512, activation='relu')(dense_layer_3)\n",
    "dense_layer_4 = Dropout(drop_out_rate)(dense_layer_4)\n",
    "dense_layer_5 = Dense(138, activation='softmax')(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network modeling with  Batch Normalization\n",
    "# with no dropout\n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 512\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1280, kernel_initializer=initializer, activation='relu' )(deep_inputs)\n",
    "# dense_layer_1 = Dropout(drop_out_rate)(dense_layer_1)\n",
    "dense_layer_1 = BatchNormalization()(dense_layer_1)\n",
    "dense_layer_2 = Dense(640, kernel_initializer=initializer, activation='relu')(dense_layer_1)\n",
    "# dense_layer_2 = Dropout(drop_out_rate)(dense_layer_2)\n",
    "dense_layer_2 = BatchNormalization()(dense_layer_2)\n",
    "dense_layer_3 = Dense(640, kernel_initializer=initializer, activation='relu')(dense_layer_2)\n",
    "# dense_layer_3 = Dropout(drop_out_rate)(dense_layer_3)\n",
    "dense_layer_3 = BatchNormalization()(dense_layer_3)\n",
    "dense_layer_4 = Dense(256, kernel_initializer=initializer, activation='relu')(dense_layer_3)\n",
    "# dense_layer_4 = Dropout(drop_out_rate)(dense_layer_4)\n",
    "dense_layer_4 = BatchNormalization()(dense_layer_4)\n",
    "dense_layer_5 = Dense(138, kernel_initializer=initializer, activation='softmax')(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_37\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_23 (InputLayer)        [(None, 40)]              0         \n_________________________________________________________________\ndense_119 (Dense)            (None, 1280)              52480     \n_________________________________________________________________\nbatch_normalization_50 (Batc (None, 1280)              5120      \n_________________________________________________________________\ndense_120 (Dense)            (None, 640)               819840    \n_________________________________________________________________\nbatch_normalization_51 (Batc (None, 640)               2560      \n_________________________________________________________________\ndense_121 (Dense)            (None, 640)               410240    \n_________________________________________________________________\nbatch_normalization_52 (Batc (None, 640)               2560      \n_________________________________________________________________\ndense_122 (Dense)            (None, 256)               164096    \n_________________________________________________________________\nbatch_normalization_53 (Batc (None, 256)               1024      \n_________________________________________________________________\ndense_123 (Dense)            (None, 138)               35466     \n=================================================================\nTotal params: 1,493,386\nTrainable params: 1,487,754\nNon-trainable params: 5,632\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.9727 - acc: 0.2550 - val_loss: 3.4705 - val_acc: 0.1530\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 52s 71ms/step - loss: 2.7586 - acc: 0.2886 - val_loss: 3.1362 - val_acc: 0.2259\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 51s 70ms/step - loss: 2.6618 - acc: 0.3069 - val_loss: 2.9388 - val_acc: 0.2573\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 53s 71ms/step - loss: 2.5837 - acc: 0.3218 - val_loss: 3.0569 - val_acc: 0.2366\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 52s 71ms/step - loss: 2.5151 - acc: 0.3347 - val_loss: 3.0956 - val_acc: 0.2271\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 53s 72ms/step - loss: 2.4506 - acc: 0.3480 - val_loss: 3.1692 - val_acc: 0.2316\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 52s 71ms/step - loss: 2.3888 - acc: 0.3600 - val_loss: 2.8726 - val_acc: 0.2740\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 54s 73ms/step - loss: 2.3277 - acc: 0.3725 - val_loss: 2.8078 - val_acc: 0.2858\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 53s 72ms/step - loss: 2.2693 - acc: 0.3848 - val_loss: 2.6975 - val_acc: 0.3068\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 52s 71ms/step - loss: 2.2128 - acc: 0.3963 - val_loss: 2.7613 - val_acc: 0.2962\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 51s 69ms/step - loss: 2.1398 - acc: 0.4127 - val_loss: 2.7278 - val_acc: 0.3070\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 53s 71ms/step - loss: 2.0688 - acc: 0.4292 - val_loss: 2.7196 - val_acc: 0.3101\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 50s 68ms/step - loss: 2.0000 - acc: 0.4430 - val_loss: 2.7261 - val_acc: 0.3156\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.9366 - acc: 0.4586 - val_loss: 2.7731 - val_acc: 0.3120\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 46s 63ms/step - loss: 1.8756 - acc: 0.4733 - val_loss: 2.7866 - val_acc: 0.3113\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 46s 63ms/step - loss: 1.8215 - acc: 0.4860 - val_loss: 2.7842 - val_acc: 0.3214\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.7688 - acc: 0.4983 - val_loss: 2.7331 - val_acc: 0.3291\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.7252 - acc: 0.5089 - val_loss: 2.8462 - val_acc: 0.3154\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.6808 - acc: 0.5195 - val_loss: 2.7704 - val_acc: 0.3307\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 46s 63ms/step - loss: 1.6409 - acc: 0.5306 - val_loss: 2.8687 - val_acc: 0.3211\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.6060 - acc: 0.5389 - val_loss: 2.8286 - val_acc: 0.3288\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.5707 - acc: 0.5484 - val_loss: 2.8616 - val_acc: 0.3278\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.5424 - acc: 0.5550 - val_loss: 2.8486 - val_acc: 0.3329\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.5144 - acc: 0.5631 - val_loss: 2.8867 - val_acc: 0.3328\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 46s 62ms/step - loss: 1.4904 - acc: 0.5695 - val_loss: 2.8673 - val_acc: 0.3345\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 46s 63ms/step - loss: 1.4659 - acc: 0.5757 - val_loss: 2.9001 - val_acc: 0.3349\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 1.4463 - acc: 0.5811 - val_loss: 2.9430 - val_acc: 0.3308\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 51s 69ms/step - loss: 1.4261 - acc: 0.5865 - val_loss: 2.9645 - val_acc: 0.3303\n",
      "Epoch 29/100\n",
      " 12/736 [..............................] - ETA: 42s - loss: 1.3790 - acc: 0.6082"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-3e38e970af80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, dummy_y, batch_size=512, callbacks=[callback], epochs=100, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network modeling with  Batch Normalization\n",
    "# with one dropout layer\n",
    "\n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 512\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1280, kernel_initializer=initializer, activation='relu' )(deep_inputs)\n",
    "# dense_layer_1 = Dropout(drop_out_rate)(dense_layer_1)\n",
    "dense_layer_1 = BatchNormalization()(dense_layer_1)\n",
    "dense_layer_2 = Dense(640, kernel_initializer=initializer, activation='relu')(dense_layer_1)\n",
    "# dense_layer_2 = Dropout(drop_out_rate)(dense_layer_2)\n",
    "dense_layer_2 = BatchNormalization()(dense_layer_2)\n",
    "dense_layer_3 = Dense(640, kernel_initializer=initializer, activation='relu')(dense_layer_2)\n",
    "dense_layer_3 = Dropout(drop_out_rate)(dense_layer_3)\n",
    "dense_layer_3 = BatchNormalization()(dense_layer_3)\n",
    "dense_layer_4 = Dense(256, kernel_initializer=initializer, activation='relu')(dense_layer_3)\n",
    "# dense_layer_4 = Dropout(drop_out_rate)(dense_layer_4)\n",
    "dense_layer_4 = BatchNormalization()(dense_layer_4)\n",
    "dense_layer_5 = Dense(138, kernel_initializer=initializer, activation='softmax')(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_39\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_24 (InputLayer)        [(None, 40)]              0         \n_________________________________________________________________\ndense_124 (Dense)            (None, 1280)              52480     \n_________________________________________________________________\nbatch_normalization_54 (Batc (None, 1280)              5120      \n_________________________________________________________________\ndense_125 (Dense)            (None, 640)               819840    \n_________________________________________________________________\nbatch_normalization_55 (Batc (None, 640)               2560      \n_________________________________________________________________\ndense_126 (Dense)            (None, 640)               410240    \n_________________________________________________________________\ndropout_63 (Dropout)         (None, 640)               0         \n_________________________________________________________________\nbatch_normalization_56 (Batc (None, 640)               2560      \n_________________________________________________________________\ndense_127 (Dense)            (None, 256)               164096    \n_________________________________________________________________\nbatch_normalization_57 (Batc (None, 256)               1024      \n_________________________________________________________________\ndense_128 (Dense)            (None, 138)               35466     \n=================================================================\nTotal params: 1,493,386\nTrainable params: 1,487,754\nNon-trainable params: 5,632\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 44s 60ms/step - loss: 3.0958 - acc: 0.2339 - val_loss: 3.5746 - val_acc: 0.1678\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 53s 72ms/step - loss: 2.8729 - acc: 0.2664 - val_loss: 3.1825 - val_acc: 0.2130\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 54s 73ms/step - loss: 2.7934 - acc: 0.2809 - val_loss: 3.0691 - val_acc: 0.2297\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.7408 - acc: 0.2916 - val_loss: 2.8543 - val_acc: 0.2714\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.6996 - acc: 0.2987 - val_loss: 2.8353 - val_acc: 0.2726\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.6685 - acc: 0.3045 - val_loss: 2.7303 - val_acc: 0.2948\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.6410 - acc: 0.3096 - val_loss: 2.8982 - val_acc: 0.2652\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.6140 - acc: 0.3145 - val_loss: 2.7435 - val_acc: 0.2879\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.5912 - acc: 0.3187 - val_loss: 2.7027 - val_acc: 0.2984\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.5732 - acc: 0.3216 - val_loss: 2.8258 - val_acc: 0.2755\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.5467 - acc: 0.3276 - val_loss: 2.6652 - val_acc: 0.3093\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.5225 - acc: 0.3321 - val_loss: 2.6560 - val_acc: 0.3089\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.4991 - acc: 0.3363 - val_loss: 2.6375 - val_acc: 0.3136\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.4792 - acc: 0.3401 - val_loss: 2.5892 - val_acc: 0.3249\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.4589 - acc: 0.3441 - val_loss: 2.5766 - val_acc: 0.3267\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.4408 - acc: 0.3475 - val_loss: 2.5959 - val_acc: 0.3232\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.4215 - acc: 0.3521 - val_loss: 2.6077 - val_acc: 0.3203\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.4074 - acc: 0.3553 - val_loss: 2.5479 - val_acc: 0.3332\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3924 - acc: 0.3577 - val_loss: 2.5588 - val_acc: 0.3291\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3785 - acc: 0.3602 - val_loss: 2.5411 - val_acc: 0.3346\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 47s 64ms/step - loss: 2.3653 - acc: 0.3630 - val_loss: 2.5160 - val_acc: 0.3397\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3555 - acc: 0.3652 - val_loss: 2.5453 - val_acc: 0.3330\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3453 - acc: 0.3675 - val_loss: 2.4953 - val_acc: 0.3451\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3359 - acc: 0.3689 - val_loss: 2.5210 - val_acc: 0.3399\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3264 - acc: 0.3708 - val_loss: 2.4956 - val_acc: 0.3455\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3197 - acc: 0.3723 - val_loss: 2.5216 - val_acc: 0.3398\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3119 - acc: 0.3747 - val_loss: 2.4856 - val_acc: 0.3474\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.3052 - acc: 0.3746 - val_loss: 2.4798 - val_acc: 0.3495\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 47s 65ms/step - loss: 2.3003 - acc: 0.3764 - val_loss: 2.4823 - val_acc: 0.3482\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2946 - acc: 0.3775 - val_loss: 2.4693 - val_acc: 0.3508\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2877 - acc: 0.3784 - val_loss: 2.4665 - val_acc: 0.3517\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2852 - acc: 0.3793 - val_loss: 2.4720 - val_acc: 0.3504\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2795 - acc: 0.3804 - val_loss: 2.4631 - val_acc: 0.3530\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2751 - acc: 0.3812 - val_loss: 2.4764 - val_acc: 0.3500\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2724 - acc: 0.3823 - val_loss: 2.4615 - val_acc: 0.3535\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2704 - acc: 0.3830 - val_loss: 2.4587 - val_acc: 0.3542\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2672 - acc: 0.3827 - val_loss: 2.4613 - val_acc: 0.3534\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2663 - acc: 0.3826 - val_loss: 2.4572 - val_acc: 0.3536\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2609 - acc: 0.3845 - val_loss: 2.4583 - val_acc: 0.3541\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2597 - acc: 0.3849 - val_loss: 2.4545 - val_acc: 0.3539\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2587 - acc: 0.3850 - val_loss: 2.4634 - val_acc: 0.3537\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2584 - acc: 0.3846 - val_loss: 2.4546 - val_acc: 0.3544\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 47s 65ms/step - loss: 2.2542 - acc: 0.3850 - val_loss: 2.4546 - val_acc: 0.3545\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2527 - acc: 0.3859 - val_loss: 2.4542 - val_acc: 0.3553\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2524 - acc: 0.3866 - val_loss: 2.4556 - val_acc: 0.3553\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2504 - acc: 0.3867 - val_loss: 2.4536 - val_acc: 0.3556\n",
      "Epoch 47/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2489 - acc: 0.3866 - val_loss: 2.4514 - val_acc: 0.3559\n",
      "Epoch 48/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2481 - acc: 0.3871 - val_loss: 2.4497 - val_acc: 0.3555\n",
      "Epoch 49/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2486 - acc: 0.3870 - val_loss: 2.4512 - val_acc: 0.3556\n",
      "Epoch 50/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2459 - acc: 0.3875 - val_loss: 2.4518 - val_acc: 0.3557\n",
      "Epoch 51/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2472 - acc: 0.3868 - val_loss: 2.4495 - val_acc: 0.3560\n",
      "Epoch 52/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2463 - acc: 0.3875 - val_loss: 2.4500 - val_acc: 0.3555\n",
      "Epoch 53/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2464 - acc: 0.3872 - val_loss: 2.4492 - val_acc: 0.3560\n",
      "Epoch 54/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2452 - acc: 0.3879 - val_loss: 2.4490 - val_acc: 0.3560\n",
      "Epoch 55/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2436 - acc: 0.3871 - val_loss: 2.4491 - val_acc: 0.3563\n",
      "Epoch 56/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2432 - acc: 0.3878 - val_loss: 2.4499 - val_acc: 0.3565\n",
      "Epoch 57/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2425 - acc: 0.3877 - val_loss: 2.4493 - val_acc: 0.3562\n",
      "Epoch 58/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2431 - acc: 0.3881 - val_loss: 2.4496 - val_acc: 0.3563\n",
      "Epoch 59/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2399 - acc: 0.3886 - val_loss: 2.4489 - val_acc: 0.3565\n",
      "Epoch 60/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2434 - acc: 0.3875 - val_loss: 2.4487 - val_acc: 0.3567\n",
      "Epoch 61/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2411 - acc: 0.3891 - val_loss: 2.4486 - val_acc: 0.3558\n",
      "Epoch 62/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2418 - acc: 0.3882 - val_loss: 2.4492 - val_acc: 0.3564\n",
      "Epoch 63/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2427 - acc: 0.3877 - val_loss: 2.4492 - val_acc: 0.3566\n",
      "Epoch 64/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2405 - acc: 0.3889 - val_loss: 2.4486 - val_acc: 0.3565\n",
      "Epoch 65/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2403 - acc: 0.3893 - val_loss: 2.4486 - val_acc: 0.3563\n",
      "Epoch 66/100\n",
      "736/736 [==============================] - 48s 66ms/step - loss: 2.2399 - acc: 0.3891 - val_loss: 2.4489 - val_acc: 0.3564\n",
      "Epoch 67/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2412 - acc: 0.3880 - val_loss: 2.4487 - val_acc: 0.3566\n",
      "Epoch 68/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2414 - acc: 0.3878 - val_loss: 2.4487 - val_acc: 0.3567\n",
      "Epoch 69/100\n",
      "736/736 [==============================] - 48s 65ms/step - loss: 2.2409 - acc: 0.3887 - val_loss: 2.4484 - val_acc: 0.3566\n",
      "Epoch 70/100\n",
      "736/736 [==============================] - 50s 68ms/step - loss: 2.2424 - acc: 0.3881 - val_loss: 2.4487 - val_acc: 0.3568\n",
      "Epoch 71/100\n",
      "736/736 [==============================] - 53s 72ms/step - loss: 2.2388 - acc: 0.3889 - val_loss: 2.4488 - val_acc: 0.3565\n",
      "Epoch 72/100\n",
      "736/736 [==============================] - 51s 70ms/step - loss: 2.2384 - acc: 0.3886 - val_loss: 2.4484 - val_acc: 0.3565\n",
      "Epoch 73/100\n",
      "736/736 [==============================] - 52s 70ms/step - loss: 2.2388 - acc: 0.3889 - val_loss: 2.4485 - val_acc: 0.3567\n",
      "Epoch 74/100\n",
      "465/736 [=================>............] - ETA: 17s - loss: 2.2406 - acc: 0.3888"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-3e38e970af80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, dummy_y, batch_size=512, callbacks=[callback], epochs=100, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.5375 - accuracy: 0.1781 - val_loss: 3.2354 - val_accuracy: 0.2134\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 3.1791 - accuracy: 0.2201 - val_loss: 3.1445 - val_accuracy: 0.2266\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 8s 10ms/step - loss: 3.1126 - accuracy: 0.2316 - val_loss: 3.0955 - val_accuracy: 0.2385\n",
      "Epoch 4/100\n",
      "730/736 [============================>.] - ETA: 0s - loss: 3.0700 - accuracy: 0.2385"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-051395619938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# neural network modeling with  Batch Normalization\n",
    "# with learning rate 0.003\n",
    "\n",
    "max_len = 40\n",
    "l1_thres = 1e-4\n",
    "l2_thres = 1e-5\n",
    "\n",
    "drop_out_rate = 0.5\n",
    "lr = 0.001\n",
    "generationsait = 250\n",
    "batch_size = 512\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "\n",
    "deep_inputs = Input(shape=(max_len,))\n",
    "dense_layer_1 = Dense(1024, kernel_initializer=initializer, activation='relu' )(deep_inputs)\n",
    "# dense_layer_1 = Dropout(drop_out_rate)(dense_layer_1)\n",
    "# dense_layer_1 = BatchNormalization()(dense_layer_1)\n",
    "# dense_layer_2 = Dense(1024, kernel_initializer=initializer, activation='relu')(dense_layer_1)\n",
    "# dense_layer_2 = Dropout(drop_out_rate)(dense_layer_2)\n",
    "# dense_layer_2 = BatchNormalization()(dense_layer_2)\n",
    "# dense_layer_3 = Dense(1024, kernel_initializer=initializer, activation='relu')(dense_layer_1)\n",
    "# dense_layer_3 = Dropout(drop_out_rate)(dense_layer_3)\n",
    "# dense_layer_3 = BatchNormalization()(dense_layer_3)\n",
    "dense_layer_4 = Dense(512, kernel_initializer=initializer, activation='relu')(dense_layer_1)\n",
    "# dense_layer_4 = Dropout(drop_out_rate)(dense_layer_4)\n",
    "# dense_layer_4 = BatchNormalization()(dense_layer_4)\n",
    "dense_layer_5 = Dense(138, kernel_initializer=initializer, activation='softmax')(dense_layer_4)\n",
    "\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_5)\n",
    "opt = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "\n",
    "history1 = model.fit(X_train, dummy_y, batch_size=512, callbacks=[callback], epochs=100, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}